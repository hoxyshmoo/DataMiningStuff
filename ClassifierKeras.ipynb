{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"D:\\\\data-mining\\\\images_compressed\\\\\" #path to where original images are stored\n",
    "path2=\"D:\\\\data-mining\\\\ClassifiedImages\\\\\" #path where images after processed are stored\n",
    "path3=\"D:\\\\data-mining\\\\test\\\\\"\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ClothingData = pd.read_csv(r\"D:\\data-mining\\images.csv\") #dataset csv path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>sender_id</th>\n",
       "      <th>label</th>\n",
       "      <th>kids</th>\n",
       "      <th>BinaryClassification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4285fab0-751a-4b74-8e9b-43af05deee22</td>\n",
       "      <td>124</td>\n",
       "      <td>Not sure</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ea7b6656-3f84-4eb3-9099-23e623fc1018</td>\n",
       "      <td>148</td>\n",
       "      <td>T-Shirt</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00627a3f-0477-401c-95eb-92642cbe078d</td>\n",
       "      <td>94</td>\n",
       "      <td>Not sure</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ea2ffd4d-9b25-4ca8-9dc2-bd27f1cc59fa</td>\n",
       "      <td>43</td>\n",
       "      <td>T-Shirt</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3b86d877-2b9e-4c8b-a6a2-1d87513309d0</td>\n",
       "      <td>189</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>dfd4079d-967b-4b3e-8574-fbac11b58103</td>\n",
       "      <td>204</td>\n",
       "      <td>Shorts</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5399</th>\n",
       "      <td>befa14be-8140-4faf-8061-1039947e329d</td>\n",
       "      <td>204</td>\n",
       "      <td>Body</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5400</th>\n",
       "      <td>5379356a-40ee-4890-b416-2336a7d84061</td>\n",
       "      <td>310</td>\n",
       "      <td>Shorts</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5401</th>\n",
       "      <td>65507fb8-3456-4c15-b53e-d1b03bf71a59</td>\n",
       "      <td>204</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5402</th>\n",
       "      <td>32b99302-cec7-4dec-adfa-3d4029674209</td>\n",
       "      <td>204</td>\n",
       "      <td>Skirt</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5403 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     image  sender_id     label   kids  \\\n",
       "0     4285fab0-751a-4b74-8e9b-43af05deee22        124  Not sure  False   \n",
       "1     ea7b6656-3f84-4eb3-9099-23e623fc1018        148   T-Shirt  False   \n",
       "2     00627a3f-0477-401c-95eb-92642cbe078d         94  Not sure  False   \n",
       "3     ea2ffd4d-9b25-4ca8-9dc2-bd27f1cc59fa         43   T-Shirt  False   \n",
       "4     3b86d877-2b9e-4c8b-a6a2-1d87513309d0        189     Shoes  False   \n",
       "...                                    ...        ...       ...    ...   \n",
       "5398  dfd4079d-967b-4b3e-8574-fbac11b58103        204    Shorts  False   \n",
       "5399  befa14be-8140-4faf-8061-1039947e329d        204      Body   True   \n",
       "5400  5379356a-40ee-4890-b416-2336a7d84061        310    Shorts  False   \n",
       "5401  65507fb8-3456-4c15-b53e-d1b03bf71a59        204     Shoes  False   \n",
       "5402  32b99302-cec7-4dec-adfa-3d4029674209        204     Skirt  False   \n",
       "\n",
       "      BinaryClassification  \n",
       "0                        0  \n",
       "1                        1  \n",
       "2                        0  \n",
       "3                        1  \n",
       "4                        2  \n",
       "...                    ...  \n",
       "5398                     3  \n",
       "5399                    10  \n",
       "5400                     3  \n",
       "5401                     2  \n",
       "5402                     6  \n",
       "\n",
       "[5403 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classlabel = []\n",
    "i=0\n",
    "for item_name in ClothingData.label: \n",
    "   if item_name==\"Not sure\":\n",
    "      classlabel.append(0)\n",
    "      \n",
    "   elif item_name==\"T-Shirt\":\n",
    "      classlabel.append(1)\n",
    "\n",
    "   elif item_name==\"Shoes\":\n",
    "      classlabel.append(2)\n",
    "      \n",
    "   elif item_name==\"Shorts\":\n",
    "      classlabel.append(3)      \n",
    "\n",
    "   elif item_name==\"Shirt\":\n",
    "      classlabel.append(4)\n",
    "      \n",
    "   elif item_name==\"Pants\":\n",
    "      classlabel.append(5)  \n",
    "   \n",
    "   elif item_name==\"Skirt\":\n",
    "      classlabel.append(6)\n",
    "      \n",
    "   elif item_name==\"Top\":\n",
    "      classlabel.append(7)\n",
    "   \n",
    "   elif item_name==\"Outwear\":\n",
    "      classlabel.append(8)\n",
    "      \n",
    "   elif item_name==\"Dress\":\n",
    "      classlabel.append(9)\n",
    "   \n",
    "   elif item_name==\"Body\":\n",
    "      classlabel.append(10)\n",
    "      \n",
    "   elif item_name==\"Longsleeve\":\n",
    "      classlabel.append(11)\n",
    "\n",
    "   elif item_name==\"Undershirt\":\n",
    "      classlabel.append(12)\n",
    "      \n",
    "   elif item_name==\"Hat\":\n",
    "      classlabel.append(13)      \n",
    "\n",
    "   elif item_name==\"Polo\":\n",
    "      classlabel.append(14)\n",
    "      \n",
    "   elif item_name==\"Blouse\":\n",
    "      classlabel.append(15)  \n",
    "   \n",
    "   elif item_name==\"Hoodie\":\n",
    "      classlabel.append(16)\n",
    "      \n",
    "   elif item_name==\"Skip\":\n",
    "      classlabel.append(17)\n",
    "   \n",
    "   elif item_name==\"Blazer\":\n",
    "      classlabel.append(18)\n",
    "   \n",
    "   elif item_name==\"Other\":\n",
    "      classlabel.append(19)\n",
    " \n",
    "   \n",
    "\n",
    "   \n",
    "\n",
    "      \n",
    "\n",
    "ClothingData['BinaryClassification'] = classlabel\n",
    "\n",
    "ClothingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407\n",
      "Found 407 files belonging to 4 classes.\n",
      "Using 326 files for training.\n",
      "Found 407 files belonging to 4 classes.\n",
      "Using 81 files for validation.\n",
      "['Blazer', 'Hoodie', 'Skirt', 'Top']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pathlib\n",
    "\n",
    "data_dir = path2\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)\n",
    "\n",
    "#split data to train and test\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 180, 180, 3)\n",
      "(32,)\n",
      "(32, 180, 180, 3)\n",
      "(32,)\n",
      "0.0023972457 1.0\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break\n",
    "\n",
    "for image_batch, labels_batch2 in val_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch2.shape)\n",
    "  break\n",
    "\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "normalization_layer = layers.Rescaling(1./255)\n",
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_1 (Rescaling)     (None, 180, 180, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 180, 180, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 90, 90, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 90, 90, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 45, 45, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 45, 45, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 22, 22, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 30976)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3965056   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,989,156\n",
      "Trainable params: 3,989,156\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "\n",
    "#model.compile(optimizer='adam',\n",
    "#             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    " #            metrics=['accuracy'])\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "    Only computes a batch-wise average of precision.\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "    Only computes a batch-wise average of recall.\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "  \n",
    "def truepositive(y_true, y_pred):\n",
    "  \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "\n",
    "    return true_positives\n",
    "\n",
    "\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer='Adam', metrics=['accuracy', precision, recall,truepositive])\n",
    "\n",
    "#model.compile(optimizer='adam', loss=keras.losses.binary_crossentropy, metrics=['accuracy', tf.keras.metrics.SensitivityAtSpecificity(0.5)])\n",
    "\n",
    "#view model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 3s 167ms/step - loss: 1.4157 - accuracy: 0.3650 - precision: 1.1213 - recall: 1.2419 - truepositive: 29.4545 - val_loss: 1.3391 - val_accuracy: 0.3704 - val_precision: 1.3283 - val_recall: 2.0139 - val_truepositive: 37.3333\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 137ms/step - loss: 1.2595 - accuracy: 0.4264 - precision: 1.8948 - recall: 1.8928 - truepositive: 40.3636 - val_loss: 1.3218 - val_accuracy: 0.3704 - val_precision: 0.9737 - val_recall: 1.6667 - val_truepositive: 32.3333\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 1.1756 - accuracy: 0.4448 - precision: 1.0772 - recall: 1.7394 - truepositive: 37.7273 - val_loss: 1.3073 - val_accuracy: 0.3580 - val_precision: 0.8080 - val_recall: 1.4702 - val_truepositive: 29.0000\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 148ms/step - loss: 1.0328 - accuracy: 0.5368 - precision: 0.8771 - recall: 1.5502 - truepositive: 33.6364 - val_loss: 1.1581 - val_accuracy: 0.4691 - val_precision: 0.9722 - val_recall: 1.6131 - val_truepositive: 31.3333\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 188ms/step - loss: 0.7649 - accuracy: 0.7055 - precision: 0.8460 - recall: 1.7064 - truepositive: 37.2727 - val_loss: 1.1938 - val_accuracy: 0.5926 - val_precision: 0.7776 - val_recall: 2.0754 - val_truepositive: 39.0000\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.5370 - accuracy: 0.8037 - precision: 0.8485 - recall: 1.8501 - truepositive: 40.2727 - val_loss: 1.1454 - val_accuracy: 0.6296 - val_precision: 0.7683 - val_recall: 1.8095 - val_truepositive: 34.6667\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 1s 117ms/step - loss: 0.3811 - accuracy: 0.8681 - precision: 0.7917 - recall: 1.7207 - truepositive: 38.0909 - val_loss: 1.0659 - val_accuracy: 0.6543 - val_precision: 0.7617 - val_recall: 1.9583 - val_truepositive: 37.3333\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 1s 119ms/step - loss: 0.2182 - accuracy: 0.9264 - precision: 0.8093 - recall: 1.7912 - truepositive: 39.3636 - val_loss: 1.0870 - val_accuracy: 0.6914 - val_precision: 0.7351 - val_recall: 2.0417 - val_truepositive: 38.6667\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.1370 - accuracy: 0.9540 - precision: 0.8027 - recall: 1.8051 - truepositive: 39.6364 - val_loss: 1.4441 - val_accuracy: 0.6173 - val_precision: 0.7618 - val_recall: 1.9960 - val_truepositive: 38.0000\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.0932 - accuracy: 0.9785 - precision: 0.7815 - recall: 1.7691 - truepositive: 38.8182 - val_loss: 1.3426 - val_accuracy: 0.6790 - val_precision: 0.7384 - val_recall: 2.0476 - val_truepositive: 38.6667\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "# plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(epochs_range, loss, label='Training Loss')\n",
    "# plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.title('Training and Validation Loss')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Value:\n",
      "[1.241866946220398, 1.8928061723709106, 1.7394077777862549, 1.5501956939697266, 1.7064118385314941, 1.8501290082931519, 1.7206686735153198, 1.791158676147461, 1.8050559759140015, 1.7691227197647095]\n",
      "[2.0138890743255615, 1.6666666269302368, 1.4702380895614624, 1.6130952835083008, 2.075396776199341, 1.8095237016677856, 1.9583333730697632, 2.0416667461395264, 1.9960317611694336, 2.047618865966797]\n",
      "Precision Value\n",
      "[1.1213077306747437, 1.8947844505310059, 1.077205777168274, 0.8770965337753296, 0.845950186252594, 0.8484963774681091, 0.7917295694351196, 0.8093149662017822, 0.8027322888374329, 0.7815141677856445]\n",
      "[1.3283225297927856, 0.9736841320991516, 0.8079822659492493, 0.9722464084625244, 0.7775521278381348, 0.7682567238807678, 0.7616685032844543, 0.735079824924469, 0.7618309855461121, 0.7383996844291687]\n",
      "True Positive Value: \n",
      "[29.454545974731445, 40.3636360168457, 37.727272033691406, 33.6363639831543, 37.272727966308594, 40.272727966308594, 38.09090805053711, 39.3636360168457, 39.6363639831543, 38.818180084228516]\n",
      "[37.33333206176758, 32.33333206176758, 29.0, 31.33333396911621, 39.0, 34.66666793823242, 37.33333206176758, 38.66666793823242, 38.0, 38.66666793823242]\n"
     ]
    }
   ],
   "source": [
    "recall = history.history['recall']\n",
    "val_recall = history.history['val_recall']\n",
    "print(\"Recall Value:\")\n",
    "print(recall)\n",
    "print(val_recall)\n",
    "\n",
    "precision = history.history['precision']\n",
    "val_precision = history.history['val_precision']\n",
    "print(\"Precision Value\")\n",
    "print(precision)\n",
    "print(val_precision)\n",
    "\n",
    "\n",
    "tp = history.history['truepositive']\n",
    "val_tp = history.history['val_truepositive']\n",
    "print(\"True Positive Value: \")\n",
    "print(tp)\n",
    "print(val_tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 91ms/step\n",
      "This image most likely belongs to Skirt with a 76.81 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "img = tf.keras.utils.load_img(\n",
    "    path3+'ee.jpg', target_size=(img_height, img_width)\n",
    ")\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)  \n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import index\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "data_dir = path3\n",
    "#data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "image_data = []\n",
    "label_data=[]\n",
    "\n",
    "# iterate over files in\n",
    "# that directory\n",
    "for images in glob.iglob(f'{data_dir}/*'):\n",
    "    #image = cv2.imread (images)\n",
    "    \n",
    "    #img = tf.keras.utils.load_img(images)\n",
    "    img_array = tf.keras.utils.img_to_array(img)\n",
    "    img_array=img_array/255\n",
    "    image_data.append (img_array)\n",
    "    i=0\n",
    "   # for c in ClothingData.index: \n",
    "    #    if os.path.basename(images)==(ClothingData[\"image\"].iloc[c]+\".jpg\"):\n",
    "    #            label_data.append(ClothingData[\"BinaryClassification\"].iloc[c])\n",
    "        \n",
    "    # check if the image ends with png\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 203 images belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mohaa\\anaconda3\\envs\\meta\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203, 97200)\n",
      "(203,)\n",
      "(203, 180, 180, 3)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Blazer       0.98      0.95      0.96        55\n",
      "      Hoodie       0.94      0.94      0.94        54\n",
      "       Skirt       0.92      0.97      0.95        72\n",
      "         Top       0.95      0.86      0.90        22\n",
      "\n",
      "    accuracy                           0.95       203\n",
      "   macro avg       0.95      0.93      0.94       203\n",
      "weighted avg       0.95      0.95      0.95       203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "test_generator = ImageDataGenerator()\n",
    "test_data_generator = test_generator.flow_from_directory(\n",
    "    path3, # Put your path here\n",
    "     target_size=(img_width, img_height),\n",
    "    batch_size=32,\n",
    "    shuffle=False)\n",
    "test_steps_per_epoch = np.math.ceil(test_data_generator.samples / test_data_generator.batch_size)\n",
    "\n",
    "predictions = model.predict_generator(test_data_generator, steps=test_steps_per_epoch)\n",
    "# Get most likely class\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "true_classes = test_data_generator.classes\n",
    "class_labels = list(test_data_generator.class_indices.keys())   \n",
    "\n",
    "\n",
    "x=np.concatenate([test_data_generator.next()[0] for i in range(test_data_generator.__len__())])\n",
    "y=np.concatenate([test_data_generator.next()[1] for i in range(test_data_generator.__len__())])\n",
    "\n",
    "pixels = x.flatten()\n",
    "pixels = x.flatten().reshape(203, 97200)\n",
    "print (pixels.shape)\n",
    "print(true_classes.shape)\n",
    "print(x.shape)\n",
    "\n",
    "\n",
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "print(report)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[52,  2,  1,  0],\n",
       "       [ 1, 51,  2,  0],\n",
       "       [ 0,  1, 70,  1],\n",
       "       [ 0,  0,  3, 19]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(true_classes, predicted_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "class estimator:\n",
    "  _estimator_type = ''\n",
    "  classes_=[]\n",
    "  def __init__(self, model, classes):\n",
    "    self.model = model\n",
    "    self._estimator_type = 'classifier'\n",
    "    self.classes_ = classes\n",
    "  def predict(self, X):\n",
    "    y_prob= self.model.predict(X)\n",
    "    y_pred = y_prob.argmax(axis=1)\n",
    "    return y_pred\n",
    "\n",
    "classifier = estimator(model, class_names)\n",
    "\n",
    "\n",
    "#figsize = (12,12)\n",
    "#plot_confusion_matrix(estimator=classifier, X=normalizedtruth, y_true=normalizedpred, cmap='Blues', normalize='true', ax=plt.subplots(figsize=figsize)[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "# Normalise\n",
    "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=1, yticklabels=1)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold, StratifiedKFold\n",
    "# import tensorflow as tf\n",
    "# #from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# idg = ImageDataGenerator(width_shift_range=0.1,\n",
    "#                          height_shift_range=0.1,\n",
    "#                          zoom_range=0.3,\n",
    "#                          fill_mode='nearest',\n",
    "#                          horizontal_flip = True,\n",
    "#                          rescale=1./255)\n",
    "\n",
    "# def get_model_name(k):\n",
    "#     return 'model_'+str(k)+'.h5'\n",
    "\n",
    "# VALIDATION_ACCURACY = []\n",
    "# VALIDAITON_LOSS = []\n",
    "\n",
    "\n",
    "# Y = ClothingData[['BinaryClassification']]\n",
    "\n",
    "# kf = KFold(n_splits = 5)\n",
    "                         \n",
    "# skf = StratifiedKFold(n_split = 5, random_state = 7, shuffle = True) \n",
    "\n",
    "\n",
    "# save_dir = '/saved_models/'\n",
    "# fold_var = 1\n",
    "\n",
    "# for train_index, val_index in kf.split(np.zeros(n),Y):\n",
    "# \ttraining_data = ClothingData.iloc[train_index]\n",
    "# \tvalidation_data = ClothingData.iloc[val_index]\n",
    "\t\n",
    "# \ttrain_data_generator = idg.flow_from_dataframe(training_data, directory = path2,\n",
    "# \t\t\t\t\t\t       x_col = \"filename\", y_col = \"label\",\n",
    "# \t\t\t\t\t\t       class_mode = \"categorical\", shuffle = True)\n",
    "# \tvalid_data_generator  = idg.flow_from_dataframe(validation_data, directory = path2,\n",
    "# \t\t\t\t\t\t\tx_col = \"filename\", y_col = \"label\",\n",
    "# \t\t\t\t\t\t\tclass_mode = \"categorical\", shuffle = True)\n",
    "\t\n",
    "# \t# CREATE NEW MODEL\n",
    "# \tmodel = create_new_model()\n",
    "# \t# COMPILE NEW MODEL\n",
    "# \tmodel.compile(loss='categorical_crossentropy',\n",
    "# \t\t      optimizer=opt,\n",
    "# \t\t      metrics=['accuracy'])\n",
    "\t\n",
    "# \t# CREATE CALLBACKS\n",
    "# \tcheckpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+get_model_name(fold_var), \n",
    "# \t\t\t\t\t\t\tmonitor='val_accuracy', verbose=1, \n",
    "# \t\t\t\t\t\t\tsave_best_only=True, mode='max')\n",
    "# \tcallbacks_list = [checkpoint]\n",
    "# \t# There can be other callbacks, but just showing one because it involves the model name\n",
    "# \t# This saves the best model\n",
    "# \t# FIT THE MODEL\n",
    "# \thistory = model.fit(train_data_generator,\n",
    "# \t\t\t    epochs=num_epochs,\n",
    "# \t\t\t    callbacks=callbacks_list,\n",
    "# \t\t\t    validation_data=valid_data_generator)\n",
    "# \t#PLOT HISTORY\n",
    "# \t#\t\t:\n",
    "# \t#\t\t:\n",
    "\t\n",
    "# \t# LOAD BEST MODEL to evaluate the performance of the model\n",
    "# \tmodel.load_weights(\"/saved_models/model_\"+str(fold_var)+\".h5\")\n",
    "\t\n",
    "# \tresults = model.evaluate(valid_data_generator)\n",
    "# \tresults = dict(zip(model.metrics_names,results))\n",
    "\t\n",
    "# \tVALIDATION_ACCURACY.append(results['accuracy'])\n",
    "# \tVALIDATION_LOSS.append(results['loss'])\n",
    "\t\n",
    "# \ttf.keras.backend.clear_session()\n",
    "\t\n",
    "# \tfold_var += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 0 1 2 1 0 2 2 2 2 0 0 2 2 0 2 0 2 2 0 0 2 0 0 0 1 2 2 0 0 0 1 1 0 0\n",
      " 1 0 2 1 2 1 0 2 0 2 0 0 2 0 2 1 1 1 2 2 1 1 0 1 2 2 0 1 1 1 1 0 0 0 2 1 2\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 102 points : 63\n",
      "61.76470588235294\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Blazer       0.41      0.62      0.49        26\n",
      "      Hoodie       0.52      0.44      0.48        27\n",
      "       Skirt       0.35      0.18      0.24        38\n",
      "         Top       0.20      0.36      0.26        11\n",
      "\n",
      "    accuracy                           0.38       102\n",
      "   macro avg       0.37      0.40      0.37       102\n",
      "weighted avg       0.39      0.38      0.37       102\n",
      "\n",
      "printing TP 12\n",
      "printing FP 11\n",
      "printing TN 16\n",
      "printing FN 23\n",
      "printing sensitivity 0.34285714285714286\n",
      "printing specificity 0.5925925925925926\n",
      "printing precision 0.5217391304347826\n",
      "printing recall 0.34285714285714286\n"
     ]
    }
   ],
   "source": [
    "from pickle import TRUE\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "X_train, X_test, y_train, y_test = train_test_split(pixels, true_classes, test_size=0.5, random_state=0)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "Gaussian_Pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0], (y_test != Gaussian_Pred).sum()))\n",
    "test=(y_test != Gaussian_Pred).sum()\n",
    "accuracy=(test/X_test.shape[0])*100\n",
    "print(accuracy)\n",
    "report = classification_report(y_test, Gaussian_Pred, target_names=class_labels)\n",
    "print(report)  \n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "\n",
    "for i in range(len(Gaussian_Pred)): \n",
    "        if y_test[i]==Gaussian_Pred[i]==1:\n",
    "           TP += 1\n",
    "        if Gaussian_Pred[i]==1 and y_test[i]!=Gaussian_Pred[i]:\n",
    "           FP += 1\n",
    "        if y_test[i]==Gaussian_Pred[i]==0:\n",
    "           TN += 1\n",
    "        if Gaussian_Pred[i]==0 and y_test[i]!=Gaussian_Pred[i]:\n",
    "           FN += 1\n",
    "TPR = TP/(TP+FN) #sensitivigty\n",
    "TNR = TN/(TN+FP) #Specificity\n",
    "PPV = TP/(TP+FP) #Precision \n",
    "\n",
    "recall = TP / (TP + FN)\n",
    "#auc = roc_auc_score(y_test, Gaussian_Pred)\n",
    "#fpr, tpr, thresholds = roc_curve(y_test, Gaussian_Pred)\n",
    "print(\"printing TP {}\" .format(TP))\n",
    "print(\"printing FP {}\" .format(FP))\n",
    "print(\"printing TN {}\" .format(TN))\n",
    "print(\"printing FN {}\" .format(FN))\n",
    "print(\"printing sensitivity {}\" .format(TPR))\n",
    "print(\"printing specificity {}\" .format(TNR))\n",
    "print(\"printing precision {}\" .format(PPV))\n",
    "print(\"printing recall {}\" .format(recall))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 102 points : 59\n",
      "57.84313725490197\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Blazer       0.41      0.62      0.49        26\n",
      "      Hoodie       0.48      0.48      0.48        27\n",
      "       Skirt       0.48      0.32      0.38        38\n",
      "         Top       0.18      0.18      0.18        11\n",
      "\n",
      "    accuracy                           0.42       102\n",
      "   macro avg       0.39      0.40      0.38       102\n",
      "weighted avg       0.43      0.42      0.41       102\n",
      "\n",
      "printing TP 13\n",
      "printing FP 14\n",
      "printing TN 16\n",
      "printing FN 23\n",
      "printing sensitivity 0.3611111111111111\n",
      "printing specificity 0.5333333333333333\n",
      "printing precision 0.48148148148148145\n",
      "printing recall 0.3611111111111111\n"
     ]
    }
   ],
   "source": [
    "from pickle import TRUE\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "X_train, X_test, y_train, y_test = train_test_split(pixels, true_classes, test_size=0.5, random_state=0)\n",
    "\n",
    "mnp = MultinomialNB()\n",
    "\n",
    "nominal_pred = mnp.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0], (y_test != nominal_pred).sum()))\n",
    "test=(y_test != nominal_pred).sum()\n",
    "accuracy=(test/X_test.shape[0])*100\n",
    "print(accuracy)\n",
    "report = classification_report(y_test, nominal_pred, target_names=class_labels)\n",
    "print(report)  \n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "\n",
    "for i in range(len(nominal_pred)): \n",
    "        if y_test[i]==nominal_pred[i]==1:\n",
    "           TP += 1\n",
    "        if nominal_pred[i]==1 and y_test[i]!=nominal_pred[i]:\n",
    "           FP += 1\n",
    "        if y_test[i]==nominal_pred[i]==0:\n",
    "           TN += 1\n",
    "        if nominal_pred[i]==0 and y_test[i]!=nominal_pred[i]:\n",
    "           FN += 1\n",
    "TPR = TP/(TP+FN) #sensitivigty\n",
    "TNR = TN/(TN+FP) #Specificity\n",
    "PPV = TP/(TP+FP) #Precision \n",
    "\n",
    "recall = TP / (TP + FN)\n",
    "#auc = roc_auc_score(y_test, nominal_pred)\n",
    "#fpr, tpr, thresholds = roc_curve(y_test, nominal_pred)\n",
    "print(\"printing TP {}\" .format(TP))\n",
    "print(\"printing FP {}\" .format(FP))\n",
    "print(\"printing TN {}\" .format(TN))\n",
    "print(\"printing FN {}\" .format(FN))\n",
    "print(\"printing sensitivity {}\" .format(TPR))\n",
    "print(\"printing specificity {}\" .format(TNR))\n",
    "print(\"printing precision {}\" .format(PPV))\n",
    "print(\"printing recall {}\" .format(recall))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 102 points : 64\n",
      "62.745098039215684\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Blazer       0.35      0.73      0.47        26\n",
      "      Hoodie       0.39      0.52      0.44        27\n",
      "       Skirt       0.50      0.13      0.21        38\n",
      "         Top       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.37       102\n",
      "   macro avg       0.31      0.35      0.28       102\n",
      "weighted avg       0.38      0.37      0.31       102\n",
      "\n",
      "printing TP 14\n",
      "printing FP 22\n",
      "printing TN 19\n",
      "printing FN 36\n",
      "printing sensitivity 0.28\n",
      "printing specificity 0.4634146341463415\n",
      "printing precision 0.3888888888888889\n",
      "printing recall 0.28\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pickle import TRUE\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "X_train, X_test, y_train, y_test = train_test_split(pixels, true_classes, test_size=0.5, random_state=0)\n",
    "\n",
    "cnp = ComplementNB()\n",
    "\n",
    "complement_pred = cnp.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0], (y_test != complement_pred).sum()))\n",
    "test=(y_test != complement_pred).sum()\n",
    "accuracy=(test/X_test.shape[0])*100\n",
    "print(accuracy)\n",
    "report = classification_report(y_test, complement_pred, target_names=class_labels)\n",
    "print(report)  \n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "\n",
    "for i in range(len(complement_pred)): \n",
    "        if y_test[i]==complement_pred[i]==1:\n",
    "           TP += 1\n",
    "        if complement_pred[i]==1 and y_test[i]!=complement_pred[i]:\n",
    "           FP += 1\n",
    "        if y_test[i]==complement_pred[i]==0:\n",
    "           TN += 1\n",
    "        if complement_pred[i]==0 and y_test[i]!=complement_pred[i]:\n",
    "           FN += 1\n",
    "TPR = TP/(TP+FN) #sensitivigty\n",
    "TNR = TN/(TN+FP) #Specificity\n",
    "PPV = TP/(TP+FP) #Precision \n",
    "\n",
    "recall = TP / (TP + FN)\n",
    "#auc = roc_auc_score(y_test, complement_pred)\n",
    "#fpr, tpr, thresholds = roc_curve(y_test, complement_pred)\n",
    "print(\"printing TP {}\" .format(TP))\n",
    "print(\"printing FP {}\" .format(FP))\n",
    "print(\"printing TN {}\" .format(TN))\n",
    "print(\"printing FN {}\" .format(FN))\n",
    "print(\"printing sensitivity {}\" .format(TPR))\n",
    "print(\"printing specificity {}\" .format(TNR))\n",
    "print(\"printing precision {}\" .format(PPV))\n",
    "print(\"printing recall {}\" .format(recall))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 102 points : 64\n",
      "62.745098039215684\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Blazer       0.00      0.00      0.00        26\n",
      "      Hoodie       0.00      0.00      0.00        27\n",
      "       Skirt       0.37      1.00      0.54        38\n",
      "         Top       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.37       102\n",
      "   macro avg       0.09      0.25      0.14       102\n",
      "weighted avg       0.14      0.37      0.20       102\n",
      "\n",
      "0\n",
      "printing TP 0\n",
      "printing FP 0\n",
      "printing TN 0\n",
      "printing FN 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mohaa\\anaconda3\\envs\\meta\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\mohaa\\anaconda3\\envs\\meta\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\mohaa\\anaconda3\\envs\\meta\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14172\\710639773.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"printing TN {}\"\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"printing FN {}\"\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0mTPR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTP\u001b[0m\u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTP\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mFN\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#sensitivigty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[0mTNR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTN\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mTN\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mFP\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Specificity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[0mPPV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTP\u001b[0m\u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTP\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mFP\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Precision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "\n",
    "from pickle import TRUE\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "X_train, X_test, y_train, y_test = train_test_split(pixels, true_classes, test_size=0.5, random_state=0)\n",
    "\n",
    "bnp = BernoulliNB()\n",
    "\n",
    "bernoulli_pred = bnp.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0], (y_test != bernoulli_pred).sum()))\n",
    "test=(y_test != bernoulli_pred).sum()\n",
    "accuracy=(test/X_test.shape[0])*100\n",
    "print(accuracy)\n",
    "report = classification_report(y_test, bernoulli_pred, target_names=class_labels)\n",
    "print(report)  \n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "\n",
    "for i in range(len(bernoulli_pred)): \n",
    "        if y_test[i]==bernoulli_pred[i]==1:\n",
    "           TP += 1\n",
    "        if bernoulli_pred[i]==1 and y_test[i]!=bernoulli_pred[i]:\n",
    "           FP += 1\n",
    "        if y_test[i]==bernoulli_pred[i]==0:\n",
    "           TN += 1\n",
    "        if bernoulli_pred[i]==0 and y_test[i]!=bernoulli_pred[i]:\n",
    "           FN += 1\n",
    "print(TP)\n",
    "print(\"printing TP {}\" .format(TP))\n",
    "print(\"printing FP {}\" .format(FP))\n",
    "print(\"printing TN {}\" .format(TN))\n",
    "print(\"printing FN {}\" .format(FN))\n",
    "TPR = TP/ (TP+FN) #sensitivigty\n",
    "TNR = TN/( TN+FP) #Specificity\n",
    "PPV = TP/ (TP+FP) #Precision \n",
    "\n",
    "recall = TP / (TP + FN)\n",
    "#auc = roc_auc_score(y_test, bernoulli_pred)\n",
    "#fpr, tpr, thresholds = roc_curve(y_test, bernoulli_pred)\n",
    "print(\"printing TP {}\" .format(TP))\n",
    "print(\"printing FP {}\" .format(FP))\n",
    "print(\"printing TN {}\" .format(TN))\n",
    "print(\"printing FN {}\" .format(FN))\n",
    "print(\"printing sensitivity {}\" .format(TPR))\n",
    "print(\"printing specificity {}\" .format(TNR))\n",
    "print(\"printing precision {}\" .format(PPV))\n",
    "print(\"printing recall {}\" .format(recall))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 250 is out of bounds for axis 1 with size 250",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5476\\57428052.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mcnx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCategoricalNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mnorm_pered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mohaa\\anaconda3\\envs\\meta\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0mjll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mohaa\\anaconda3\\envs\\meta\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1459\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1461\u001b[1;33m             \u001b[0mjll\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_log_prob_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1462\u001b[0m         \u001b[0mtotal_ll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjll\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_log_prior_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1463\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtotal_ll\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 250 is out of bounds for axis 1 with size 250"
     ]
    }
   ],
   "source": [
    "from pickle import TRUE\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "X_train, X_test, y_train, y_test = train_test_split(pixels, true_classes, test_size=0.5, random_state=0)\n",
    "\n",
    "cnx = CategoricalNB()\n",
    "\n",
    "norm_pered = cnx.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0], (y_test != norm_pered).sum()))\n",
    "test=(y_test != norm_pered).sum()\n",
    "accuracy=(test/X_test.shape[0])*100\n",
    "print(accuracy)\n",
    "report = classification_report(y_test, norm_pered, target_names=class_labels)\n",
    "print(report)  \n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "\n",
    "for i in range(len(norm_pered)): \n",
    "        if y_test[i]==norm_pered[i]==1:\n",
    "           TP += 1\n",
    "        if norm_pered[i]==1 and y_test[i]!=norm_pered[i]:\n",
    "           FP += 1\n",
    "        if y_test[i]==norm_pered[i]==0:\n",
    "           TN += 1\n",
    "        if norm_pered[i]==0 and y_test[i]!=norm_pered[i]:\n",
    "           FN += 1\n",
    "TPR = TP/(TP+FN) #sensitivigty\n",
    "TNR = TN/(TN+FP) #Specificity\n",
    "PPV = TP/(TP+FP) #Precision \n",
    "\n",
    "recall = TP / (TP + FN)\n",
    "#auc = roc_auc_score(y_test, norm_pered)\n",
    "#fpr, tpr, thresholds = roc_curve(y_test, norm_pered)\n",
    "print(\"printing TP {}\" .format(TP))\n",
    "print(\"printing FP {}\" .format(FP))\n",
    "print(\"printing TN {}\" .format(TN))\n",
    "print(\"printing FN {}\" .format(FN))\n",
    "print(\"printing sensitivity {}\" .format(TPR))\n",
    "print(\"printing specificity {}\" .format(TNR))\n",
    "print(\"printing precision {}\" .format(PPV))\n",
    "print(\"printing recall {}\" .format(recall))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('meta')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e31c64a5e57a7ad3e7d4ccef763047826fc431f17b1d5a9c833ac52fc326693"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
