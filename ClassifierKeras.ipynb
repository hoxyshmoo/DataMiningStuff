{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"C:\\\\Users\\\\Adam\\\\Documents\\\\Python Scripts\\\\ClothesDataset\\\\images_compressed\\\\\" #path to where original images are stored\n",
    "path2=\"C:\\\\Users\\\\Adam\\\\Documents\\\\Python Scripts\\\\ClothesDataset\\\\ClassifiedImages\\\\\" #path where images after processed are stored\n",
    "path3=\"C:\\\\Users\\\\Adam\\\\Documents\\\\Python Scripts\\\\ClothesDataset\\\\testdata\\\\\"\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ClothingData = pd.read_csv(r\"C:\\Users\\Adam\\Documents\\Python Scripts\\ClothesDataset\\images.csv\") #dataset csv path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>sender_id</th>\n",
       "      <th>label</th>\n",
       "      <th>kids</th>\n",
       "      <th>BinaryClassification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4285fab0-751a-4b74-8e9b-43af05deee22</td>\n",
       "      <td>124</td>\n",
       "      <td>Not sure</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ea7b6656-3f84-4eb3-9099-23e623fc1018</td>\n",
       "      <td>148</td>\n",
       "      <td>T-Shirt</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00627a3f-0477-401c-95eb-92642cbe078d</td>\n",
       "      <td>94</td>\n",
       "      <td>Not sure</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ea2ffd4d-9b25-4ca8-9dc2-bd27f1cc59fa</td>\n",
       "      <td>43</td>\n",
       "      <td>T-Shirt</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3b86d877-2b9e-4c8b-a6a2-1d87513309d0</td>\n",
       "      <td>189</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>dfd4079d-967b-4b3e-8574-fbac11b58103</td>\n",
       "      <td>204</td>\n",
       "      <td>Shorts</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5399</th>\n",
       "      <td>befa14be-8140-4faf-8061-1039947e329d</td>\n",
       "      <td>204</td>\n",
       "      <td>Body</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5400</th>\n",
       "      <td>5379356a-40ee-4890-b416-2336a7d84061</td>\n",
       "      <td>310</td>\n",
       "      <td>Shorts</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5401</th>\n",
       "      <td>65507fb8-3456-4c15-b53e-d1b03bf71a59</td>\n",
       "      <td>204</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5402</th>\n",
       "      <td>32b99302-cec7-4dec-adfa-3d4029674209</td>\n",
       "      <td>204</td>\n",
       "      <td>Skirt</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5403 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     image  sender_id     label   kids  \\\n",
       "0     4285fab0-751a-4b74-8e9b-43af05deee22        124  Not sure  False   \n",
       "1     ea7b6656-3f84-4eb3-9099-23e623fc1018        148   T-Shirt  False   \n",
       "2     00627a3f-0477-401c-95eb-92642cbe078d         94  Not sure  False   \n",
       "3     ea2ffd4d-9b25-4ca8-9dc2-bd27f1cc59fa         43   T-Shirt  False   \n",
       "4     3b86d877-2b9e-4c8b-a6a2-1d87513309d0        189     Shoes  False   \n",
       "...                                    ...        ...       ...    ...   \n",
       "5398  dfd4079d-967b-4b3e-8574-fbac11b58103        204    Shorts  False   \n",
       "5399  befa14be-8140-4faf-8061-1039947e329d        204      Body   True   \n",
       "5400  5379356a-40ee-4890-b416-2336a7d84061        310    Shorts  False   \n",
       "5401  65507fb8-3456-4c15-b53e-d1b03bf71a59        204     Shoes  False   \n",
       "5402  32b99302-cec7-4dec-adfa-3d4029674209        204     Skirt  False   \n",
       "\n",
       "      BinaryClassification  \n",
       "0                        0  \n",
       "1                        1  \n",
       "2                        0  \n",
       "3                        1  \n",
       "4                        2  \n",
       "...                    ...  \n",
       "5398                     3  \n",
       "5399                    10  \n",
       "5400                     3  \n",
       "5401                     2  \n",
       "5402                     6  \n",
       "\n",
       "[5403 rows x 5 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classlabel = []\n",
    "i=0\n",
    "for item_name in ClothingData.label: \n",
    "   if item_name==\"Not sure\":\n",
    "      classlabel.append(0)\n",
    "      \n",
    "   elif item_name==\"T-Shirt\":\n",
    "      classlabel.append(1)\n",
    "\n",
    "   elif item_name==\"Shoes\":\n",
    "      classlabel.append(2)\n",
    "      \n",
    "   elif item_name==\"Shorts\":\n",
    "      classlabel.append(3)      \n",
    "\n",
    "   elif item_name==\"Shirt\":\n",
    "      classlabel.append(4)\n",
    "      \n",
    "   elif item_name==\"Pants\":\n",
    "      classlabel.append(5)  \n",
    "   \n",
    "   elif item_name==\"Skirt\":\n",
    "      classlabel.append(6)\n",
    "      \n",
    "   elif item_name==\"Top\":\n",
    "      classlabel.append(7)\n",
    "   \n",
    "   elif item_name==\"Outwear\":\n",
    "      classlabel.append(8)\n",
    "      \n",
    "   elif item_name==\"Dress\":\n",
    "      classlabel.append(9)\n",
    "   \n",
    "   elif item_name==\"Body\":\n",
    "      classlabel.append(10)\n",
    "      \n",
    "   elif item_name==\"Longsleeve\":\n",
    "      classlabel.append(11)\n",
    "\n",
    "   elif item_name==\"Undershirt\":\n",
    "      classlabel.append(12)\n",
    "      \n",
    "   elif item_name==\"Hat\":\n",
    "      classlabel.append(13)      \n",
    "\n",
    "   elif item_name==\"Polo\":\n",
    "      classlabel.append(14)\n",
    "      \n",
    "   elif item_name==\"Blouse\":\n",
    "      classlabel.append(15)  \n",
    "   \n",
    "   elif item_name==\"Hoodie\":\n",
    "      classlabel.append(16)\n",
    "      \n",
    "   elif item_name==\"Skip\":\n",
    "      classlabel.append(17)\n",
    "   \n",
    "   elif item_name==\"Blazer\":\n",
    "      classlabel.append(18)\n",
    "   \n",
    "   elif item_name==\"Other\":\n",
    "      classlabel.append(19)\n",
    " \n",
    "   \n",
    "\n",
    "   \n",
    "\n",
    "      \n",
    "\n",
    "ClothingData['BinaryClassification'] = classlabel\n",
    "\n",
    "ClothingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407\n",
      "Found 407 files belonging to 4 classes.\n",
      "Using 326 files for training.\n",
      "Found 407 files belonging to 4 classes.\n",
      "Using 81 files for validation.\n",
      "['Blazer', 'Hoodie', 'Skirt', 'Top']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pathlib\n",
    "\n",
    "data_dir = path2\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)\n",
    "\n",
    "#split data to train and test\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 180, 180, 3)\n",
      "(32,)\n",
      "(32, 180, 180, 3)\n",
      "(32,)\n",
      "0.011437222 0.9764053\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break\n",
    "\n",
    "for image_batch, labels_batch2 in val_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch2.shape)\n",
    "  break\n",
    "\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "normalization_layer = layers.Rescaling(1./255)\n",
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_7 (Rescaling)     (None, 180, 180, 3)       0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 180, 180, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 90, 90, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 90, 90, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 45, 45, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 45, 45, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 22, 22, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 30976)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               3965056   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,989,156\n",
      "Trainable params: 3,989,156\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "\n",
    "#model.compile(optimizer='adam',\n",
    "#             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    " #            metrics=['accuracy'])\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "    Only computes a batch-wise average of precision.\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "    Only computes a batch-wise average of recall.\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "  \n",
    "def truepositive(y_true, y_pred):\n",
    "  \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "\n",
    "    return true_positives\n",
    "\n",
    "\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer='Adam', metrics=['accuracy', precision, recall,truepositive])\n",
    "\n",
    "#model.compile(optimizer='adam', loss=keras.losses.binary_crossentropy, metrics=['accuracy', tf.keras.metrics.SensitivityAtSpecificity(0.5)])\n",
    "\n",
    "#view model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 4s 316ms/step - loss: 1.7057 - accuracy: 0.3466 - precision: 30909090.0000 - recall: 1.0148 - truepositive: 23.6364 - val_loss: 1.3239 - val_accuracy: 0.3704 - val_precision: 1.2805 - val_recall: 1.0933 - val_truepositive: 20.3333\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 3s 246ms/step - loss: 1.2686 - accuracy: 0.4172 - precision: 1.5771 - recall: 1.2277 - truepositive: 27.3636 - val_loss: 1.3061 - val_accuracy: 0.3704 - val_precision: 0.9659 - val_recall: 1.1885 - val_truepositive: 22.6667\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 3s 229ms/step - loss: 1.1370 - accuracy: 0.5184 - precision: 0.9882 - recall: 1.2650 - truepositive: 28.0000 - val_loss: 1.1977 - val_accuracy: 0.4444 - val_precision: 0.8431 - val_recall: 1.5714 - val_truepositive: 29.6667\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.9442 - accuracy: 0.6350 - precision: 0.9026 - recall: 1.4437 - truepositive: 31.3636 - val_loss: 1.1769 - val_accuracy: 0.5432 - val_precision: 0.8244 - val_recall: 1.4802 - val_truepositive: 28.0000\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.7426 - accuracy: 0.7117 - precision: 0.7943 - recall: 1.5491 - truepositive: 33.6364 - val_loss: 1.3121 - val_accuracy: 0.5556 - val_precision: 0.6892 - val_recall: 1.7917 - val_truepositive: 33.6667\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 196ms/step - loss: 0.5739 - accuracy: 0.7791 - precision: 0.7713 - recall: 1.8224 - truepositive: 40.1818 - val_loss: 1.0841 - val_accuracy: 0.5556 - val_precision: 0.7782 - val_recall: 2.2282 - val_truepositive: 42.3333\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 197ms/step - loss: 0.4032 - accuracy: 0.8834 - precision: 0.7513 - recall: 2.0724 - truepositive: 45.7273 - val_loss: 1.1750 - val_accuracy: 0.5432 - val_precision: 0.7812 - val_recall: 2.4742 - val_truepositive: 47.0000\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 195ms/step - loss: 0.2775 - accuracy: 0.9172 - precision: 0.7487 - recall: 1.9530 - truepositive: 42.7273 - val_loss: 1.0597 - val_accuracy: 0.5556 - val_precision: 0.7422 - val_recall: 2.1706 - val_truepositive: 41.3333\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 195ms/step - loss: 0.2419 - accuracy: 0.9233 - precision: 0.7583 - recall: 1.9278 - truepositive: 42.1818 - val_loss: 1.0986 - val_accuracy: 0.5679 - val_precision: 0.7332 - val_recall: 2.0258 - val_truepositive: 38.3333\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 196ms/step - loss: 0.1564 - accuracy: 0.9663 - precision: 0.7398 - recall: 1.8562 - truepositive: 40.4545 - val_loss: 1.2654 - val_accuracy: 0.6049 - val_precision: 0.7378 - val_recall: 2.1607 - val_truepositive: 41.0000\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "# plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(epochs_range, loss, label='Training Loss')\n",
    "# plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.title('Training and Validation Loss')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Value:\n",
      "[1.0148138999938965, 1.227749228477478, 1.2650099992752075, 1.4437211751937866, 1.549076795578003, 1.8223553895950317, 2.072392702102661, 1.952966570854187, 1.9278193712234497, 1.8562337160110474]\n",
      "[1.0932539701461792, 1.188491940498352, 1.5714284181594849, 1.480158805847168, 1.7916666269302368, 2.2281744480133057, 2.4742062091827393, 2.1706349849700928, 2.0257937908172607, 2.1607143878936768]\n",
      "Precision Value\n",
      "[30909090.0, 1.577088475227356, 0.988193154335022, 0.9026346206665039, 0.7943332195281982, 0.7712998986244202, 0.7513074278831482, 0.7486705780029297, 0.7583248615264893, 0.7398224472999573]\n",
      "[1.2805218696594238, 0.965867817401886, 0.8430877327919006, 0.8243746161460876, 0.6891581416130066, 0.7782285213470459, 0.7811636328697205, 0.7422016263008118, 0.7331745028495789, 0.7378066182136536]\n",
      "True Positive Value: \n",
      "[23.636363983154297, 27.363636016845703, 28.0, 31.363636016845703, 33.6363639831543, 40.181819915771484, 45.727272033691406, 42.727272033691406, 42.181819915771484, 40.45454406738281]\n",
      "[20.33333396911621, 22.66666603088379, 29.66666603088379, 28.0, 33.66666793823242, 42.33333206176758, 47.0, 41.33333206176758, 38.33333206176758, 41.0]\n"
     ]
    }
   ],
   "source": [
    "recall = history.history['recall']\n",
    "val_recall = history.history['val_recall']\n",
    "print(\"Recall Value:\")\n",
    "print(recall)\n",
    "print(val_recall)\n",
    "\n",
    "precision = history.history['precision']\n",
    "val_precision = history.history['val_precision']\n",
    "print(\"Precision Value\")\n",
    "print(precision)\n",
    "print(val_precision)\n",
    "\n",
    "\n",
    "tp = history.history['truepositive']\n",
    "val_tp = history.history['val_truepositive']\n",
    "print(\"True Positive Value: \")\n",
    "print(tp)\n",
    "print(val_tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 95ms/step\n",
      "This image most likely belongs to Hoodie with a 99.78 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "img = tf.keras.utils.load_img(\n",
    "    path3+'Hoodie//2c74a33c-4267-4bd0-946c-0dd214183f5b.jpg', target_size=(img_height, img_width)\n",
    ")\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)  \n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import index\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "data_dir = path3\n",
    "#data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "image_data = []\n",
    "label_data=[]\n",
    "\n",
    "# iterate over files in\n",
    "# that directory\n",
    "for images in glob.iglob(f'{data_dir}/*'):\n",
    "    #image = cv2.imread (images)\n",
    "    \n",
    "    #img = tf.keras.utils.load_img(images)\n",
    "    img_array = tf.keras.utils.img_to_array(img)\n",
    "    img_array=img_array/255\n",
    "    image_data.append (img_array)\n",
    "    i=0\n",
    "   # for c in ClothingData.index: \n",
    "    #    if os.path.basename(images)==(ClothingData[\"image\"].iloc[c]+\".jpg\"):\n",
    "    #            label_data.append(ClothingData[\"BinaryClassification\"].iloc[c])\n",
    "        \n",
    "    # check if the image ends with png\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 203 images belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_21936\\1067396726.py:13: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  predictions = model.predict_generator(test_data_generator, steps=test_steps_per_epoch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203, 97200)\n",
      "(203,)\n",
      "(203, 180, 180, 3)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Blazer       0.93      0.93      0.93        55\n",
      "      Hoodie       0.81      0.94      0.87        54\n",
      "       Skirt       0.93      0.88      0.90        72\n",
      "         Top       1.00      0.77      0.87        22\n",
      "\n",
      "    accuracy                           0.90       203\n",
      "   macro avg       0.92      0.88      0.89       203\n",
      "weighted avg       0.90      0.90      0.90       203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "test_generator = ImageDataGenerator()\n",
    "test_data_generator = test_generator.flow_from_directory(\n",
    "    path3, # Put your path here\n",
    "     target_size=(img_width, img_height),\n",
    "    batch_size=32,\n",
    "    shuffle=False)\n",
    "test_steps_per_epoch = np.math.ceil(test_data_generator.samples / test_data_generator.batch_size)\n",
    "\n",
    "predictions = model.predict_generator(test_data_generator, steps=test_steps_per_epoch)\n",
    "# Get most likely class\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "true_classes = test_data_generator.classes\n",
    "class_labels = list(test_data_generator.class_indices.keys())   \n",
    "\n",
    "\n",
    "x=np.concatenate([test_data_generator.next()[0] for i in range(test_data_generator.__len__())])\n",
    "y=np.concatenate([test_data_generator.next()[1] for i in range(test_data_generator.__len__())])\n",
    "\n",
    "pixels = x.flatten()\n",
    "pixels = x.flatten().reshape(203, 97200)\n",
    "print (pixels.shape)\n",
    "print(true_classes.shape)\n",
    "print(x.shape)\n",
    "\n",
    "\n",
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "print(report)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[51,  4,  0,  0],\n",
       "       [ 1, 51,  2,  0],\n",
       "       [ 3,  6, 63,  0],\n",
       "       [ 0,  2,  3, 17]], dtype=int64)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(true_classes, predicted_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "class estimator:\n",
    "  _estimator_type = ''\n",
    "  classes_=[]\n",
    "  def __init__(self, model, classes):\n",
    "    self.model = model\n",
    "    self._estimator_type = 'classifier'\n",
    "    self.classes_ = classes\n",
    "  def predict(self, X):\n",
    "    y_prob= self.model.predict(X)\n",
    "    y_pred = y_prob.argmax(axis=1)\n",
    "    return y_pred\n",
    "\n",
    "classifier = estimator(model, class_names)\n",
    "\n",
    "\n",
    "#figsize = (12,12)\n",
    "#plot_confusion_matrix(estimator=classifier, X=normalizedtruth, y_true=normalizedpred, cmap='Blues', normalize='true', ax=plt.subplots(figsize=figsize)[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "# Normalise\n",
    "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=1, yticklabels=1)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold, StratifiedKFold\n",
    "# import tensorflow as tf\n",
    "# #from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# idg = ImageDataGenerator(width_shift_range=0.1,\n",
    "#                          height_shift_range=0.1,\n",
    "#                          zoom_range=0.3,\n",
    "#                          fill_mode='nearest',\n",
    "#                          horizontal_flip = True,\n",
    "#                          rescale=1./255)\n",
    "\n",
    "# def get_model_name(k):\n",
    "#     return 'model_'+str(k)+'.h5'\n",
    "\n",
    "# VALIDATION_ACCURACY = []\n",
    "# VALIDAITON_LOSS = []\n",
    "\n",
    "\n",
    "# Y = ClothingData[['BinaryClassification']]\n",
    "\n",
    "# kf = KFold(n_splits = 5)\n",
    "                         \n",
    "# skf = StratifiedKFold(n_split = 5, random_state = 7, shuffle = True) \n",
    "\n",
    "\n",
    "# save_dir = '/saved_models/'\n",
    "# fold_var = 1\n",
    "\n",
    "# for train_index, val_index in kf.split(np.zeros(n),Y):\n",
    "# \ttraining_data = ClothingData.iloc[train_index]\n",
    "# \tvalidation_data = ClothingData.iloc[val_index]\n",
    "\t\n",
    "# \ttrain_data_generator = idg.flow_from_dataframe(training_data, directory = path2,\n",
    "# \t\t\t\t\t\t       x_col = \"filename\", y_col = \"label\",\n",
    "# \t\t\t\t\t\t       class_mode = \"categorical\", shuffle = True)\n",
    "# \tvalid_data_generator  = idg.flow_from_dataframe(validation_data, directory = path2,\n",
    "# \t\t\t\t\t\t\tx_col = \"filename\", y_col = \"label\",\n",
    "# \t\t\t\t\t\t\tclass_mode = \"categorical\", shuffle = True)\n",
    "\t\n",
    "# \t# CREATE NEW MODEL\n",
    "# \tmodel = create_new_model()\n",
    "# \t# COMPILE NEW MODEL\n",
    "# \tmodel.compile(loss='categorical_crossentropy',\n",
    "# \t\t      optimizer=opt,\n",
    "# \t\t      metrics=['accuracy'])\n",
    "\t\n",
    "# \t# CREATE CALLBACKS\n",
    "# \tcheckpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+get_model_name(fold_var), \n",
    "# \t\t\t\t\t\t\tmonitor='val_accuracy', verbose=1, \n",
    "# \t\t\t\t\t\t\tsave_best_only=True, mode='max')\n",
    "# \tcallbacks_list = [checkpoint]\n",
    "# \t# There can be other callbacks, but just showing one because it involves the model name\n",
    "# \t# This saves the best model\n",
    "# \t# FIT THE MODEL\n",
    "# \thistory = model.fit(train_data_generator,\n",
    "# \t\t\t    epochs=num_epochs,\n",
    "# \t\t\t    callbacks=callbacks_list,\n",
    "# \t\t\t    validation_data=valid_data_generator)\n",
    "# \t#PLOT HISTORY\n",
    "# \t#\t\t:\n",
    "# \t#\t\t:\n",
    "\t\n",
    "# \t# LOAD BEST MODEL to evaluate the performance of the model\n",
    "# \tmodel.load_weights(\"/saved_models/model_\"+str(fold_var)+\".h5\")\n",
    "\t\n",
    "# \tresults = model.evaluate(valid_data_generator)\n",
    "# \tresults = dict(zip(model.metrics_names,results))\n",
    "\t\n",
    "# \tVALIDATION_ACCURACY.append(results['accuracy'])\n",
    "# \tVALIDATION_LOSS.append(results['loss'])\n",
    "\t\n",
    "# \ttf.keras.backend.clear_session()\n",
    "\t\n",
    "# \tfold_var += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 0 1 2 1 0 2 2 2 2 0 0 2 2 0 2 0 2 2 0 0 2 0 0 0 1 2 2 0 0 0 1 1 0 0\n",
      " 1 0 2 1 2 1 0 2 0 2 0 0 2 0 2 1 1 1 2 2 1 1 0 1 2 2 0 1 1 1 1 0 0 0 2 1 2\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 47.  47.  47. ...  80.  80.  80.]\n",
      " [ 98.  98.  98. ...  88.  88.  88.]\n",
      " [151. 151. 151. ...  92.  92.  92.]\n",
      " ...\n",
      " [211. 211. 211. ... 135. 135. 135.]\n",
      " [205. 205. 205. ... 208. 208. 208.]\n",
      " [ 53.  53.  53. ...  36.  36.  36.]]\n",
      "[2 0 0 2 2 1 0 2 2 0 1 0 1 3 1 3 0 0 3 3 1 3 1 3 2 1 1 2 0 1 2 0 2 3 0 2 0\n",
      " 1 1 3 3 0 1 1 0 1 0 0 0 0 3 0 3 0 0 1 0 0 2 1 2 1 3 1 0 3 1 0 0 0 3 3 2 1\n",
      " 1 2 2 2 0 0 3 2 0 0 0 2 2 1 0 3 3 3 0 0 0 0 3 0 0 1 0 2]\n",
      "Number of mislabeled points out of a total 102 points : 63\n",
      "61.76470588235294\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Blazer       0.41      0.62      0.49        26\n",
      "      Hoodie       0.52      0.44      0.48        27\n",
      "       Skirt       0.35      0.18      0.24        38\n",
      "         Top       0.20      0.36      0.26        11\n",
      "\n",
      "    accuracy                           0.38       102\n",
      "   macro avg       0.37      0.40      0.37       102\n",
      "weighted avg       0.39      0.38      0.37       102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(pixels, true_classes, test_size=0.5, random_state=0)\n",
    "print(X_train)\n",
    "gnb = GaussianNB()\n",
    "\n",
    "Gaussian_Pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "print(Gaussian_Pred)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0], (y_test != Gaussian_Pred).sum()))\n",
    "test=(y_test != Gaussian_Pred).sum()\n",
    "accuracy=(test/X_test.shape[0])*100\n",
    "print(accuracy)\n",
    "report = classification_report(y_test, Gaussian_Pred, target_names=class_labels)\n",
    "print(report)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('F21DL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1d7d42b81cbd0a5eddf30639e13072384a73a3f22291508b04d3e2d9ab09ddc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
